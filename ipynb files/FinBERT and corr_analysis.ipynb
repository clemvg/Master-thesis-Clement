{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Database\"\n",
    "usdataset = \"/news_df.csv\"\n",
    "totalpath = path + usdataset\n",
    "df = pd.read_csv(totalpath)\n",
    "df['release_date'] = pd.to_datetime(df['release_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two columns in df: sentiment title and sentiment body\n",
    "df['sentiment_title'] = np.nan\n",
    "df['sentiment_body'] = np.nan\n",
    "df['sentiment_body'] = df['sentiment_body'].astype(object)\n",
    "df['sentiment_title'] = df['sentiment_title'].astype(object)\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import FinBERT\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did this ones for the news headlines and ones for the news bodies. Csv files sentimentheadlines_postFINBERT and bodies_sentiment_postFINBERT show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = []\n",
    "for i in range(len(df)):\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Processed\", i, \"values\")\n",
    "\n",
    "    text = df['content'][i]\n",
    "\n",
    "    try:\n",
    "        encoded_input = tokenizer(text, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        puts = F.softmax(output.logits, dim=1)\n",
    "        puts = puts.detach().numpy()\n",
    "\n",
    "        positive_score = puts[0][0]\n",
    "        negative_score = puts[0][1]\n",
    "        neutral_score = puts[0][2]\n",
    "\n",
    "        sentiment_score = (positive_score,negative_score,neutral_score)\n",
    "        sentiment_score = np.round(sentiment_score, 3)\n",
    "        puts = np.array(sentiment_score)\n",
    "\n",
    "        df[\"sentiment_body\"][i]=puts\n",
    "    except RuntimeError:\n",
    "        print(f\"Skipping article {i} due to RuntimeError\")\n",
    "        #create a list with all the index of the articles that are too long\n",
    "        list_index.append(i)\n",
    "        continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here saving first sentiment score obtained by FinBERT. Results are loaded again in following section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load sentiment data scores -correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_price = \"../Database/price.csv\"\n",
    "price = pd.read_csv(path_price)\n",
    "price = price[['Date','Close']]\n",
    "#create extra column % difference with daily close price difference\n",
    "price['% Daily diff'] = price['Close'].pct_change()\n",
    "price['Date'] = pd.to_datetime(price['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TICKERS PROP\n",
    "totalpath = path + \"/ticker_prop.csv\"\n",
    "ticker_prop = pd.read_csv(totalpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bodies\n",
    "totalpath = path + \"/sentimentbodies_postFINBERT.csv\"\n",
    "bodies = pd.read_csv(totalpath)\n",
    "bodies['release_date'] = pd.to_datetime(bodies['release_date'])\n",
    "#create columns\n",
    "bodies['diff'] = 0\n",
    "bodies['rmax'] = 0\n",
    "bodies['max'] = 0\n",
    "bodies['sigmoid'] = 0\n",
    "bodies['weights'] = 0\n",
    "bodies['abs_max'] = 0\n",
    "bodies['discrete_max'] = 0\n",
    "bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headlines\n",
    "totalpath = path + \"/sentimentheadlines_postFINBERT.csv\"\n",
    "headlines = pd.read_csv(totalpath)\n",
    "headlines['release_date'] = pd.to_datetime(headlines['release_date'])\n",
    "headlines['diff'] = 0\n",
    "headlines['rmax'] = 0\n",
    "headlines['max'] = 0\n",
    "headlines['sigmoid'] = 0\n",
    "headlines['weights'] = 0\n",
    "headlines['abs_max'] = 0\n",
    "headlines['discrete_max'] = 0\n",
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import stats\n",
    "# colors = ['#228A83', '#002060', '#7A5F3F']\n",
    "# columns = ['positive', 'negative', 'neutral']\n",
    "# #print kde of of positive, negative and neutral sentiment in dataframe sentiment\n",
    "# for i in columns:\n",
    "#     sns.kdeplot(headlines[i], shade=True, color=colors[columns.index(i)])\n",
    "\n",
    "# #add a legend\n",
    "# plt.legend(labels=['positive', 'negative', 'neutral'])\n",
    "# #add title x axis 'probability score'\n",
    "# plt.xlabel('probability score')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bodies and headlines merged\n",
    "bodies1 = bodies[['release_date','positive', 'negative', 'neutral','diff','rmax','max','sigmoid','weights','abs_max','discrete_max']]\n",
    "sentiment1 = headlines[['release_date','positive', 'negative', 'neutral','diff','rmax','max','sigmoid','weights','abs_max','discrete_max']]\n",
    "#merge bodies1 and sentiment1\n",
    "merged = sentiment1.append(bodies1, ignore_index=True)\n",
    "merged = merged.sort_values(by=['release_date'])\n",
    "merged = merged.reset_index(drop=True)\n",
    "merged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Converting 3 polarity sentiment scores to one score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 sentiment formulas are outlined below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff\n",
    "headlines['diff'] = headlines.apply(lambda row: row['positive'] - row['negative'], axis=1)\n",
    "\n",
    "#weights\n",
    "pos_weight = 0.5\n",
    "neg_weight = 0.5\n",
    "neu_weight = 0\n",
    "\n",
    "headlines['weights'] = headlines.apply(lambda row: pos_weight * row['positive'] + neg_weight * row['negative'] + neu_weight * row['neutral'], axis=1)\n",
    "\n",
    "#score ratio\n",
    "headlines['sratio'] = headlines.apply(lambda row: row['positive'] / row['negative'] if row['negative'] != 0 else 0, axis=1)\n",
    "\n",
    "#max\n",
    "headlines['max'] = headlines[['positive', 'negative']].max(axis=1)\n",
    "\n",
    "#sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_official(pos_score, neg_score, neu_score):\n",
    "    x = pos_score - neg_score\n",
    "    final_score = sigmoid(x)\n",
    "    return final_score\n",
    "headlines['sigmoid'] = headlines.apply(lambda row: sigmoid_official(row['positive'], row['negative'], row['neutral']), axis=1)\n",
    "\n",
    "def discrete_max(pos_score, neg_score, neu_score):\n",
    "    if pos_score > neg_score and pos_score > neu_score:\n",
    "        final_score = 1\n",
    "    elif neg_score > pos_score and neg_score > neu_score:\n",
    "        final_score = -1\n",
    "    else:\n",
    "        final_score = 0\n",
    "    return final_score\n",
    "\n",
    "headlines['discrete_max'] = headlines.apply(lambda row: discrete_max(row['positive'], row['negative'], row['neutral']), axis=1)\n",
    "\n",
    "\n",
    "#abs_max\n",
    "def abs_max(pos_score, neg_score, neu_score):\n",
    "    final_score=max(pos_score, neg_score, neu_score)\n",
    "    if final_score == pos_score:\n",
    "        final_score= pos_score\n",
    "    elif final_score == neg_score:\n",
    "        final_score= -neg_score\n",
    "    else:\n",
    "        final_score= 0\n",
    "    return final_score\n",
    "\n",
    "headlines['abs_max'] = headlines.apply(lambda row: abs_max(row['positive'], row['negative'], row['neutral']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete columns positive negative neutral and headlines title\n",
    "headlines = headlines.drop(['positive', 'negative', 'neutral', 'Sentiment title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep a copy\n",
    "sentiment_copy = sentiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff\n",
    "bodies['diff'] = bodies.apply(lambda row: row['positive'] - row['negative'], axis=1)\n",
    "\n",
    "#weights\n",
    "pos_weight = 0.5\n",
    "neg_weight = 0.5\n",
    "neu_weight = 0\n",
    "\n",
    "bodies['weights'] = bodies.apply(lambda row: pos_weight * row['positive'] + neg_weight * row['negative'] + neu_weight * row['neutral'], axis=1)\n",
    "\n",
    "#score ratio\n",
    "bodies['sratio'] = bodies.apply(lambda row: row['positive'] / row['negative'] if row['negative'] != 0 else 0, axis=1)\n",
    "\n",
    "#max\n",
    "bodies['max'] = bodies[['positive', 'negative']].max(axis=1)\n",
    "\n",
    "#sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_official(pos_score, neg_score, neu_score):\n",
    "    x = pos_score - neg_score\n",
    "    final_score = sigmoid(x)\n",
    "    return final_score\n",
    "bodies['sigmoid'] = bodies.apply(lambda row: sigmoid_official(row['positive'], row['negative'], row['neutral']), axis=1)\n",
    "\n",
    "def discrete_max(pos_score, neg_score, neu_score):\n",
    "    if pos_score > neg_score and pos_score > neu_score:\n",
    "        final_score = 1\n",
    "    elif neg_score > pos_score and neg_score > neu_score:\n",
    "        final_score = -1\n",
    "    else:\n",
    "        final_score = 0\n",
    "    return final_score\n",
    "\n",
    "bodies['discrete_max'] = bodies.apply(lambda row: discrete_max(row['positive'], row['negative'], row['neutral']), axis=1)\n",
    "\n",
    "\n",
    "#abs_max\n",
    "def abs_max(pos_score, neg_score, neu_score):\n",
    "    final_score=max(pos_score, neg_score, neu_score)\n",
    "    if final_score == pos_score:\n",
    "        final_score= pos_score\n",
    "    elif final_score == neg_score:\n",
    "        final_score= -neg_score\n",
    "    else:\n",
    "        final_score= 0\n",
    "    return final_score\n",
    "\n",
    "bodies['abs_max'] = bodies.apply(lambda row: abs_max(row['positive'], row['negative'], row['neutral']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete columns positive negative neutral and bodies title\n",
    "bodies = bodies.drop(['positive', 'negative', 'neutral', 'sentiment_body', 'content'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies_copy  = bodies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headlines + bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff\n",
    "merged['diff'] = merged.apply(lambda row: row['positive'] - row['negative'], axis=1)\n",
    "\n",
    "#weights\n",
    "pos_weight = 0.5\n",
    "neg_weight = 0.5\n",
    "neu_weight = 0\n",
    "\n",
    "merged['weights'] = merged.apply(lambda row: pos_weight * row['positive'] + neg_weight * row['negative'] + neu_weight * row['neutral'], axis=1)\n",
    "\n",
    "#score ratio\n",
    "merged['sratio'] = merged.apply(lambda row: row['positive'] / row['negative'] if row['negative'] != 0 else 0, axis=1)\n",
    "\n",
    "#max\n",
    "merged['max'] = merged[['positive', 'negative']].max(axis=1)\n",
    "\n",
    "def sigmoid(pos_score, neg_score, neu_score):\n",
    "    x = pos_score - neg_score\n",
    "    final_score = 1 / (1 + np.exp(-x))\n",
    "    return final_score\n",
    "merged['sigmoid'] = merged.apply(lambda row: sigmoid(row['positive'], row['negative'], row['neutral']), axis=1)\n",
    "\n",
    "def discrete_max(pos_score, neg_score, neu_score):\n",
    "    if pos_score > neg_score and pos_score > neu_score:\n",
    "        final_score = 1\n",
    "    elif neg_score > pos_score and neg_score > neu_score:\n",
    "        final_score = -1\n",
    "    else:\n",
    "        final_score = 0\n",
    "    return final_score\n",
    "\n",
    "merged['discrete_max'] = merged.apply(lambda row: discrete_max(row['positive'], row['negative'], row['neutral']), axis=1)\n",
    "\n",
    "\n",
    "#abs_max\n",
    "def abs_max(pos_score, neg_score, neu_score):\n",
    "    final_score=max(pos_score, neg_score, neu_score)\n",
    "    if final_score == pos_score:\n",
    "        final_score= pos_score\n",
    "    elif final_score == neg_score:\n",
    "        final_score= -neg_score\n",
    "    else:\n",
    "        final_score= 0\n",
    "    return final_score\n",
    "\n",
    "merged['abs_max'] = merged.apply(lambda row: abs_max(row['positive'], row['negative'], row['neutral']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete columns positive negative neutral and merged title\n",
    "merged = merged.drop(['positive', 'negative', 'neutral'], axis=1)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_copy = merged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = headlines.groupby(['ticker', 'release_date']).mean()\n",
    "headlines = headlines.groupby(['release_date']).mean()\n",
    "\n",
    "bodies = bodies.groupby(['ticker', 'release_date']).mean()\n",
    "bodies = bodies.groupby(['release_date']).mean()\n",
    "\n",
    "merged = merged.groupby(['ticker', 'release_date']).mean()\n",
    "merged = merged.groupby(['release_date']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_dif_array = price['% Daily diff'].to_numpy()\n",
    "price_array = price['Close'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create for each column in sentiment: diff, sratio, max, sigmoid, weights a different numpy array_sentiment\n",
    "diff_array_sentiment = sentiment['diff'].to_numpy()\n",
    "sratio_array_sentiment = sentiment['sratio'].to_numpy()\n",
    "sigmoid_array_sentiment = sentiment['sigmoid'].to_numpy()\n",
    "weights_array_sentiment = sentiment['weights'].to_numpy()\n",
    "max_array_sentiment = sentiment['max'].to_numpy()\n",
    "abs_max_array_sentiment = sentiment['abs_max'].to_numpy()\n",
    "discrete_max_array_sentiment = sentiment['discrete_max'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create for each column in bodies: diff, sratio, max, sigmoid, weights a different numpy array_bodies\n",
    "diff_array_bodies = bodies['diff'].to_numpy()\n",
    "sratio_array_bodies = bodies['sratio'].to_numpy()\n",
    "sigmoid_array_bodies = bodies['sigmoid'].to_numpy()\n",
    "weights_array_bodies = bodies['weights'].to_numpy()\n",
    "max_array_bodies = bodies['max'].to_numpy()\n",
    "abs_max_array_bodies = bodies['abs_max'].to_numpy()\n",
    "discrete_max_array_bodies = bodies['discrete_max'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create for each column in merged: diff, sratio, max, sigmoid, weights a different numpy array_merged\n",
    "diff_array_merged = merged['diff'].to_numpy()\n",
    "sratio_array_merged = merged['sratio'].to_numpy()\n",
    "sigmoid_array_merged = merged['sigmoid'].to_numpy()\n",
    "weights_array_merged = merged['weights'].to_numpy()\n",
    "max_array_merged = merged['max'].to_numpy()\n",
    "abs_max_array_merged = merged['abs_max'].to_numpy()\n",
    "discrete_max_array_merged = merged['discrete_max'].to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare two vectors(!) of length 755\n",
    "Scatterplot with linear regression\n",
    "Moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for price_dif_array and price_array add zero at the beginning and two zeros at the end\n",
    "price_dif_array = np.insert(price_dif_array, 0, 0)\n",
    "price_dif_array = np.append(price_dif_array, [0, 0])\n",
    "price_dif_array.shape\n",
    "price_array = np.insert(price_array, 0, 0)\n",
    "price_array = np.append(price_array, [0, 0])\n",
    "price_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_diff_before = price_array[:-3]\n",
    "price_diff_intraday = price_array[1:-2]\n",
    "price_diff_1day = price_array[2:-1]\n",
    "price_diff_2days = price_array[3:]\n",
    "\n",
    "close_diff_before = close_array[:-3]\n",
    "close_diff_intraday = close_array[1:-2]\n",
    "close_diff_1day = close_array[2:-1]\n",
    "close_diff_2days = close_array[3:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price= price_diff_before #variable to change\n",
    "pearson_table = pd.DataFrame(columns=['Differencing', 'Score ratio', 'Sigmoid', 'Weights', 'Adapted maximum', 'Discrete maximum'])\n",
    "pearson_table.loc['Headlines'] = [pearsonr(diff_array_sentiment, price)[0], pearsonr(sratio_array_sentiment, price)[0], pearsonr(sigmoid_array_sentiment, price)[0], pearsonr(weights_array_sentiment, price)[0], pearsonr(abs_max_array_sentiment, price)[0], pearsonr(discrete_max_array_sentiment, price)[0]]\n",
    "pearson_table.loc['Bodies'] = [pearsonr(diff_array_bodies, price)[0], pearsonr(sratio_array_bodies, price)[0], pearsonr(sigmoid_array_bodies, price)[0], pearsonr(weights_array_bodies, price)[0], pearsonr(abs_max_array_bodies, price)[0], pearsonr(discrete_max_array_bodies, price)[0]]\n",
    "pearson_table.loc['Headlines and bodies'] = [pearsonr(diff_array_merged, price)[0], pearsonr(sratio_array_merged, price)[0], pearsonr(sigmoid_array_merged, price)[0], pearsonr(weights_array_merged, price)[0], pearsonr(abs_max_array_merged, price)[0], pearsonr(discrete_max_array_merged, price)[0]]\n",
    "pearson_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION\n",
    "X = np.array([sentiment_data]).T\n",
    "y = np.array([prix]).T\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "# Print regression coefficients\n",
    "print(\"Regression Coefficients:\")\n",
    "print(f\"Intercept: {reg.intercept_[0]:.3f}\")\n",
    "print(f\"Sentiment: {reg.coef_[0][0]:.3f}\")\n",
    "\n",
    "# Print R-squared value\n",
    "r2 = reg.score(X, y)\n",
    "print(f\"R-squared: {r2:.3f}\")\n",
    "\n",
    "# Visualize the regression results\n",
    "plt.scatter(X, y, c = '#228A83')\n",
    "plt.plot(X, reg.predict(X), color=\"#FFC000\")\n",
    "plt.xlabel(\"Intraday news bodies & headlines sentiment scores\", color = '#2E5651')\n",
    "plt.ylabel(\"Daily % price differences\", color = '#2E5651')\n",
    "plt.title(\"Differencing method\", fontsize=10, color = '#2E5651')\n",
    "#print Regression Coefficients:Intercept Sentiment: R-squared\n",
    "\n",
    "corr, _ = pearsonr(prix,sentiment_data) # CORRELATION\n",
    "plt.text(-0.55, 0.06, f\"Pearson correlation: {0.365}\", fontsize=9, color = '#2E5651')\n",
    "plt.text(-0.55, 0.055, f\"Intercept: {reg.intercept_[0]:.3f}\", fontsize=9, color = '#2E5651')\n",
    "plt.text(-0.55, 0.05, f\"Slope: {reg.coef_[0][0]:.3f}\", fontsize=9, color = '#2E5651')\n",
    "plt.text(-0.55, 0.045, f\"R-squared: {r2:.3f}\", fontsize=9, color = '#2E5651')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sentiment_data_std = scaler.fit_transform(sentiment_data.reshape(-1,1))\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "prix_std = scaler1.fit_transform(prix.reshape(-1, 1))\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "price_data_std = scaler2.fit_transform(close_array.reshape(-1,1))\n",
    "\n",
    "#flattent the arrays\n",
    "sentiment_data_std = sentiment_data_std.flatten()\n",
    "prix_std = prix_std.flatten()\n",
    "price_data_std = price_data_std.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving average\n",
    "\n",
    "x = 30 #best for the moment\n",
    "sentiment_rolling = pd.Series(sentiment_data_std).rolling(window=x).mean()\n",
    "price_rolling = pd.Series(prix_std).rolling(window=x).mean()\n",
    "adj_close = pd.Series(price_data_std).rolling(window=x).mean()\n",
    "#show correlation between sentimment rolling and price rolling\n",
    "# corr, _ = pearsonr(sentiment_rolling,price_rolling)\n",
    "# print('Pearsons correlation: %.3f' % corr)\n",
    "plt.plot(sentiment_rolling, label=\"Sentiment scores\", color = '#228A83')\n",
    "plt.plot(adj_close, label=\"Adj Close price\", color = '#002060')\n",
    "# plt.plot(adj_close, label=\"Price\", color = '#C00000')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\", color = '#2E5651')\n",
    "plt.ylabel(\"Moving Average\", color = '#2E5651')\n",
    "plt.title(\"Price-sentiment intraday moving average\", fontsize=10,fontweight='bold', color = '#2E5651')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best time series sentiment which is intraday sentiment with ticker proportion\n",
    "np.save('sentiment_data.npy', sentiment_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
